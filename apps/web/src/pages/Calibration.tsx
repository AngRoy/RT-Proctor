import React, { useEffect, useRef, useState } from 'react'
import { useNavigate } from 'react-router-dom'
export default function Calibration(){
  const sessionId='demo-session'
  const [step,setStep]=useState(1)
  const [msg,setMsg]=useState('Grant camera + mic permissions.')
  const [state,setState]=useState<any>(null)
  const videoRef=useRef<HTMLVideoElement>(null)
  const camStream=useRef<MediaStream|null>(null)
  const wsRef=useRef<WebSocket|null>(null)
  const audioWS=useRef<WebSocket|null>(null)
  const audioCtx=useRef<AudioContext|null>(null)
  const nav=useNavigate()
  useEffect(()=>{ fetch('/api/calibration/start',{method:'POST',headers:{'Content-Type':'application/json','x-exam':localStorage.getItem('exam_token')||''},body:JSON.stringify({session_id:sessionId})}) },[])
  async function refreshState(){ const r=await fetch(`/api/calibration/state?session_id=${sessionId}`,{headers:{'x-exam':localStorage.getItem('exam_token')||''}}); if(r.ok){ setState(await r.json()) } }
  useEffect(()=>{ const t=setInterval(refreshState,800); return ()=> clearInterval(t) },[])
  useEffect(()=>{ wsRef.current=new WebSocket(`ws://`+location.host+`/api/session/${sessionId}/events?token=${localStorage.getItem('exam_token')||''}`); return ()=> wsRef.current?.close() },[])
  useEffect(()=>{ (async()=>{ try{ camStream.current=await navigator.mediaDevices.getUserMedia({video:true,audio:false}); if(videoRef.current){ videoRef.current.srcObject=camStream.current; await videoRef.current.play() } }catch{} })() },[])
  function sendFrame(prompt?:string){ const v=videoRef.current; if(!v||v.videoWidth===0) return; const can=document.createElement('canvas'); can.width=v.videoWidth; can.height=v.videoHeight; const g=can.getContext('2d')!; g.drawImage(v,0,0); const jpegB64=can.toDataURL('image/jpeg',0.6); wsRef.current?.send(JSON.stringify({t:'frame',phase:'calib',prompt,jpegB64})) }
  async function startAudioEnroll(){ audioCtx.current=new AudioContext(); const stream=await navigator.mediaDevices.getUserMedia({audio:true,video:false}); const ws=new WebSocket(`ws://`+location.host+`/api/session/${sessionId}/audio?token=${localStorage.getItem('exam_token')||''}`); audioWS.current=ws; const source=audioCtx.current.createMediaStreamSource(stream); const proc=audioCtx.current.createScriptProcessor(4096,1,1); source.connect(proc); proc.connect(audioCtx.current.destination); let seq=0; proc.onaudioprocess=(ev)=>{ const buf=ev.inputBuffer.getChannelData(0); const pcm=new Int16Array(buf.length); for(let i=0;i<buf.length;i++){ let s=Math.max(-1,Math.min(1,buf[i])); pcm[i]= s<0? s*0x8000 : s*0x7fff } if(ws.readyState===1){ ws.send(JSON.stringify({seq:seq++,mode:'calib_enroll',rate:16000,ms:25})); ws.send(pcm) } } }
  const canNext=()=>{ if(!state) return false; const st=state.state; if(step===1) return !!(st?.hardware?.camera_ok); if(step===2) return !!(st?.hardware?.mic_ok); if(step===3) return st?.video?.CENTER; if(step===4) return st?.video?.LEFT; if(step===5) return st?.video?.RIGHT; if(step===6) return st?.video?.UP; if(step===7) return st?.video?.DOWN; if(step===8) return state?.ready; return false }
  async function next(){ if(!canNext()) return; if(step===1){ setStep(2); setMsg('Speak the enrollment phrase (about 12s).'); await startAudioEnroll() } else if(step===2){ setStep(3); setMsg('Look CENTER.'); sendFrame('CENTER') } else if(step===3){ setStep(4); setMsg('Turn LEFT.'); sendFrame('LEFT') } else if(step===4){ setStep(5); setMsg('Turn RIGHT.'); sendFrame('RIGHT') } else if(step===5){ setStep(6); setMsg('Look UP.'); sendFrame('UP') } else if(step===6){ setStep(7); setMsg('Look DOWN.'); sendFrame('DOWN') } else if(step===7){ setStep(8); setMsg('Final checks…'); const r=await fetch('/api/calibration/finalize',{method:'POST',headers:{'Content-Type':'application/json','x-exam':localStorage.getItem('exam_token')||''},body:JSON.stringify({session_id:sessionId})}); if(!r.ok){ const j=await r.json(); alert('Calibration incomplete: '+(j.missing||[]).join(', ')) } else { setMsg('Calibrated. Continue to exam.'); try{ const a=new (window.AudioContext||(window as any).webkitAudioContext)(); const o=a.createOscillator(); const g=a.createGain(); o.connect(g).connect(a.destination); g.gain.value=0.001; o.frequency.value=880; o.start(); g.gain.exponentialRampToValueAtTime(0.2,a.currentTime+0.05); g.gain.exponentialRampToValueAtTime(0.001,a.currentTime+0.35); o.stop(a.currentTime+0.4) }catch{} } } else { nav('/problem') } }
  return <div className='card'><h2>Calibration</h2><div className='badges'><div className='badge'>Camera <b className={state?.state?.hardware?.camera_ok?'ok':'no'}>{state?.state?.hardware?.camera_ok?'✔':'✖'}</b></div><div className='badge'>Mic <b className={state?.state?.hardware?.mic_ok?'ok':'no'}>{state?.state?.hardware?.mic_ok?'✔':'✖'}</b></div><div className='badge'>No Headphones <b className={state?.state?.hardware?.no_headphones?'ok':'no'}>{state?.state?.hardware?.no_headphones?'✔':'✖'}</b></div></div><p>{msg}</p><div className='row'><div className='card'><video ref={videoRef} style={{width:'100%',borderRadius:8}} muted playsInline/><div style={{marginTop:8}}>Poses: CENTER {state?.state?.video?.CENTER?'✔':'·'} • LEFT {state?.state?.video?.LEFT?'✔':'·'} • RIGHT {state?.state?.video?.RIGHT?'✔':'·'} • UP {state?.state?.video?.UP?'✔':'·'} • DOWN {state?.state?.video?.DOWN?'✔':'·'}</div></div><div className='card'><div>Enrollment phrase:</div><code>i agree to follow the exam rules i am the registered candidate and i will not seek assistance</code></div></div><div style={{marginTop:12}}><button className='btn' onClick={next} disabled={!canNext()}>Next</button></div></div>
}
